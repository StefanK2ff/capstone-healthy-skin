{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a template for building a CNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and inital setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.applications import MobileNetV3Large\n",
    "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.legacy import SGD\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from helperfunctions import modelhelper as mh\n",
    "from helperfunctions import imagehelper as ih\n",
    "\n",
    "SEED = 856\n",
    "NUM_EPOCHS = 6\n",
    "\n",
    "# File path variables\n",
    "# please make sure to use the correct path to the meta data file\n",
    "\n",
    "FILEPATH_JPGS = './../data/jpgs/'\n",
    "FILEPATH_PROCESSED=\"./../data/processed/\"\n",
    "FILEPATH_OUTPUT = './../data/jpgs/'  # Replace with your folder path\n",
    "\n",
    "TARGET_LABEL=\"dx_binary\"\n",
    "\n",
    "IMAGE_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading (augmented) metadata as test, train, validation from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the metadata file\n",
    "train_df = pd.read_csv(FILEPATH_PROCESSED+\"train_from_Metadata_processed.csv\")\n",
    "validation_df = pd.read_csv(FILEPATH_PROCESSED+\"validation_from_Metadata_processed.csv\")\n",
    "test_df = pd.read_csv(FILEPATH_PROCESSED+\"test_from_Metadata_processed.csv\")\n",
    "\n",
    "train_df.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the image data generator for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_preprocessing(np_image, image_size):\n",
    "    np_image = ih.center_crop_image(np_image) # Crop image to square format\n",
    "    np_image = ih.resize_as_preprocess(np_image, image_size) # resize the image\n",
    "    np_image = preprocess_input(np_image) # Apply the preprocess_input function of MobileNetV3Large\n",
    "    return np_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the Image Data Generator for the train data set\n",
    "\n",
    "datagen_train = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0, # Rescale pixel values to [0, 1], important for CNNs to perform better\n",
    "    preprocessing_function=lambda x: custom_preprocessing(x, IMAGE_SIZE), # Apply the custom preprocessing function \n",
    ")\n",
    "\n",
    "datagen_validation = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,\n",
    "    preprocessing_function=lambda x: custom_preprocessing(x, IMAGE_SIZE)\n",
    ")\n",
    "\n",
    "validation_generator = datagen_validation.flow_from_dataframe(\n",
    "    dataframe=validation_df,\n",
    "    directory=FILEPATH_JPGS,\n",
    "    x_col=\"image_id\",\n",
    "    y_col=TARGET_LABEL,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "train_data_generator = datagen_train.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory=FILEPATH_JPGS,\n",
    "        x_col=\"image_id\",\n",
    "        y_col=TARGET_LABEL,\n",
    "        class_mode=\"categorical\",\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using MobileNet V3 large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    # Calculate precision\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "    # Calculate recall\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "\n",
    "    # Calculate F1 score\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(alpha=0.25, gamma=2.0):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1 + K.epsilon())) \\\n",
    "               -K.sum((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0 + K.epsilon()))\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, verbose=1, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED = True\n",
    "\n",
    "if PRETRAINED:\n",
    "    # Initialize the MobileNetV3Large model\n",
    "    base_model = MobileNetV3Large(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
    "\n",
    "    print(base_model.output_shape)\n",
    "\n",
    "    # Freeze the base model's layers to use it for feature extraction\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Add custom layers on top \n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(base_model.output)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu')(x)\n",
    "\n",
    "    # Global average pooling instead of flattening\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)  # 50% dropout /new\n",
    "\n",
    "    x = layers.Dense(train_df[TARGET_LABEL].nunique(), activation='sigmoid')(x) \n",
    "\n",
    "    # Create the full model\n",
    "    model = Model(inputs=base_model.input, outputs=x, name=\"MobilneNetV3Large_pretrained-weights_binary_fixed-layers_custom-conv2D\")\n",
    "\n",
    "    # Setting an optimizer\n",
    "    opt = SGD(learning_rate=0.0001, \n",
    "                momentum=0.9\n",
    "                # nesterov=True,\n",
    "                # decay=0.01\n",
    "              )\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=opt,\n",
    "                loss='binary_crossentropy',\n",
    "                #loss = focal_loss(),\n",
    "                metrics=[\n",
    "                        #Recall(), \n",
    "                        #Precision(), \n",
    "                        'accuracy',\n",
    "                        f1_score\n",
    "                        ])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "else:\n",
    "    # Initialize the MobileNetV3Large model\n",
    "    base_model = MobileNetV3Large(weights=None, include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
    "\n",
    "    # Freeze the base model's layers to use it for feature extraction\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Add custom layers on top \n",
    "    x = layers.Flatten()(base_model.output)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dense(train_df[TARGET_LABEL].nunique(), activation='sigmoid')(x) \n",
    "\n",
    "    # Create the full model\n",
    "    model = Model(inputs=base_model.input, outputs=x, name=\"MobilneNetV3Large_rand-weights\")\n",
    "\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "history = model.fit(\n",
    "    train_data_generator,\n",
    "    epochs=NUM_EPOCHS,              \n",
    "    verbose=1,                      # Adjust verbosity level\n",
    "    batch_size=None,                # Set the batch size, default is 32, can be increased to speed up training\n",
    "    callbacks=[reduce_lr],                 # List of callbacks to apply during training \n",
    "    validation_split=0.0,           # not needed as we use a validation data generator\n",
    "    validation_data=validation_generator,\n",
    "    shuffle=True,                   # Shuffle the training data before each epoch\n",
    "    sample_weight=None,             # Set the weights for the train data set !\n",
    "    class_weight=None,              # Set the weights for the classes, not needed if we use sample weights\n",
    "    initial_epoch=0,                # Use this to continue training from a specific epoch\n",
    "    steps_per_epoch=None,           # Set the number of steps per epoch, default is len(x_train) // batch_size\n",
    "    validation_steps=None,          # Set the number of steps for validation, default is len(x_val) // batch_size\n",
    "    validation_batch_size=None,     # Set the batch size for validation, default is batch_size\n",
    "    validation_freq=1,              # Only relevant if validation data is a generator. Set the frequency to validate the model on the validation set\n",
    "    max_queue_size=10,              # Set the max size for the generator queue\n",
    "    workers=-1,                     # Set the max number of processes to generate the data in parallel, -1 means all CPUs\n",
    "    use_multiprocessing=False       # Set to True if you use a generator in parallel, e.g. model.predict_generator()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting accuracy and loss of train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mh.model_plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh.model_accuracy_on_test(model, test_df, TARGET_LABEL, IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "timestamp = datetime.now()\n",
    "model_path = f\"../models/model_{timestamp}.h5\"\n",
    "model.save(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
