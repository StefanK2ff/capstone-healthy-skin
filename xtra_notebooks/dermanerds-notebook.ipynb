{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### This Notebook processes the Metadata file and writes a new CSV file.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checks if the processed folder exists and if not creates it\npath =  '/kaggle/working/processed/'\ndirectory = os.path.dirname(path)\nif not os.path.exists(directory):\n    os.makedirs(directory)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import table from tab file\ndataframe = pd.read_csv('/kaggle/input/dermanerds-project/HAM10000_metadata', delimiter=',')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#change endings of image_id to .jpg\ndataframe['image_id'] = dataframe['image_id'].apply(lambda x: x + '.jpg')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pool mel,bcc,akiec into skin cancer category in new column dx_binary\ndataframe['dx_binary'] = np.where(dataframe['dx'].isin(['mel','bcc','akiec']), 'skin_cancer', 'not_skin_cancer')\n\ndataframe['dx_tertiary'] = np.where(dataframe['dx_binary'] == 'skin_cancer', 'malignant', np.where(dataframe['dx'].isin(['bkl', 'vasc', 'df']), 'non-neoplastic', 'benign'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#impute missing values in age column with median\ndataframe['age'].fillna(dataframe['age'].median(), inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#save as csv\ndataframe.to_csv('/kaggle/working/processed/Metadata_processed.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA -  HAM10000 - Metadata","metadata":{}},{"cell_type":"markdown","source":"## 1 Importing Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2 Importing Data","metadata":{}},{"cell_type":"code","source":"#import table from tab file\ndataframe = pd.read_csv('/kaggle/input/dermanerds-project/HAM10000_metadata', delimiter=',')\n# load processed metadata\nprocessed_dataframe = pd.read_csv('/kaggle/working/processed/Metadata_processed.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\n\n# Create the 'jpgs' directory in the working directory\nos.makedirs('/kaggle/working/jpgs', exist_ok=True)\n\n# Copy the contents of HAM10000_images_part_1 and HAM10000_images_part_2 into jpgs\nsrc_dirs = ['/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1', \n            '/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2']\n\nfor src_dir in src_dirs:\n    for filename in os.listdir(src_dir):\n        filepath = os.path.join(src_dir, filename)\n        if os.path.isfile(filepath):\n            shutil.copy(filepath, '/kaggle/working/jpgs')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3 Data Exploration","metadata":{}},{"cell_type":"markdown","source":"### Context of raw features and their values","metadata":{}},{"cell_type":"markdown","source":"Ham10000_metadata consists of 8 features.\n1. **lesion_id** - unique id per lesion\n2. **image_id** - unique id per image taken of lesion\n3. **dx** contains diagnosis with the following values\n* \"bkl\" - benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses)\n* \"nv\" - melanocytic nevi (normal moles)\n* \"df\" - dermatofibroma (small scar after insect bite etc.)\n* \"vasc\" - vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage)\n* \"mel\" = melanoma (Skin cancer 1)\n* \"bcc\" = basal cell carcinoma (Skin cancer 2)\n* \"akiec\" = actinic keratoses and intraepithelial carcinoma / Bowen's disease (Skin cancer 3)\n4. **dx_type** diagnosis confirmed by\n* \"histo\" - through histopathology\n* \"consensus\" - expert consensus\n* \"confocal\" - in-vivo confocal microscopy\n* \"follow_up\" - follow-up examination\n5. **age** of patients\n6. **sex** of patients\n* \"male\"\n* \"female\"\n* \"unknown\"\n    \n7. **localization** of the lesion\n* \"scalp\"\n* \"ear\"\n* \"face\"\n* \"back\"\n* \"trunk\"\n* \"chest\"\n* \"abdomen\"\n* \"genital\"\n* \"neck\"\n* \"hand\"\n* \"foot\"\n* \"acral\"\n* \"lower extremity\"\n* \"upper extremnity\"\n* \"unknown\"\n    \n8. **dataset** source of observation\n* \"vidir_modern\"\n* \"rosendahl\"\n* \"vienna_dias\"\n* \"vidir_molemax\"","metadata":{}},{"cell_type":"markdown","source":"### Quick first check","metadata":{}},{"cell_type":"code","source":"def count_column_types(df: pd.DataFrame) -> dict[str, int]:\n    # Count the number of columns of each type in a DataFrame\n    dtypes: pd.Series = df.dtypes\n    return {\n        'text': (dtypes == 'object').sum(),\n        'categorical': (dtypes == 'category').sum(),\n        'numerical': dtypes.apply(lambda x: pd.api.types.is_numeric_dtype(x)).sum()\n    }","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"HAM10000 - metadata:\")\nprint(\"There are\", dataframe.shape[1], \"features with\", dataframe.shape[0],\"observations.\")\nprint(\"---------------------------------\")\nprint(\"Count of textbased features:\", count_column_types(dataframe)[\"text\"])\nprint(\"Count of categorical features:\", count_column_types(dataframe)[\"categorical\"])\nprint(\"Count of numerical features:\", count_column_types(dataframe)[\"numerical\"])\nprint(\"---------------------------------\")\nprint(\"Number of duplicated rows:\", dataframe.duplicated().sum())\nprint(\"Number of missing values:\", dataframe.isnull().sum().sum())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Quick look at the table of the raw dataframe.","metadata":{}},{"cell_type":"code","source":"# show first 10 rows\ndataframe.head(10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show last 10 rows\ndataframe.tail(10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.1 Descriptive Statistics - Tendency and measuring\n\nIn the preprocessed raw dataframe we have 8 features:  \n* lesion_id,\n* image_id\n* dx\n* dx_type\n* age\n* sex\n* localization\n* dataset","metadata":{}},{"cell_type":"markdown","source":"#### lesion_id","metadata":{}},{"cell_type":"markdown","source":"Unique Values, Missing Values","metadata":{}},{"cell_type":"code","source":"# Analyze feature \"lesion_id\"\nprint(\"Number of unique values in feature 'lesion_id':\", dataframe[\"lesion_id\"].nunique())\nprint(\"Relative number of unique values in feature 'lesion_id':\", round(dataframe[\"lesion_id\"].nunique()/dataframe.shape[0]*100), \"%\")\nprint(\"Number of missing values in feature 'lesion_id':\", dataframe[\"lesion_id\"].isnull().sum())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sum of lesion_id with more than one image","metadata":{}},{"cell_type":"code","source":"lesions_more_than_one_image = dataframe[dataframe[\"lesion_id\"].map(dataframe[\"lesion_id\"].value_counts()) > 1]\nprint(\"Sum of lesion_ids with more than one image taken:\", lesions_more_than_one_image[['lesion_id']].nunique()[0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are lesion_ids that come with more than one image. It is assumed that these photos of a lesion_id were taken multiple times to achieve better image quality.","metadata":{}},{"cell_type":"markdown","source":"#### image_id","metadata":{}},{"cell_type":"markdown","source":"Unique Values, Missing Values","metadata":{}},{"cell_type":"code","source":"# Analyze feature \"image_id\"\nprint(\"Number of unique values in feature 'image_id':\", dataframe[\"image_id\"].nunique())\nprint(\"Relative number of unique values in feature 'image_id':\", round(dataframe[\"image_id\"].nunique()/dataframe.shape[0]*100), \"%\")\nprint(\"Number of missing values in feature 'image_id':\", dataframe[\"image_id\"].isnull().sum())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sum of image_id with more than one lesion:","metadata":{}},{"cell_type":"code","source":"# check if there are image_ids with more than one lesion_id\nimage_ids_more_than_one_lesion = dataframe[dataframe[\"image_id\"].map(dataframe[\"image_id\"].value_counts()) > 1]\nprint(\"Sum of image_ids with more than one lesion:\", image_ids_more_than_one_lesion[['image_id']].nunique()[0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So it looks like the image_id is a unique key.","metadata":{}},{"cell_type":"markdown","source":"#### dx","metadata":{}},{"cell_type":"markdown","source":"Unique Values, Missing Values","metadata":{}},{"cell_type":"code","source":"# Analyze feature \"dx\"\nprint(\"Number of unique values in feature 'dx':\", dataframe[\"dx\"].nunique())\nprint(\"Number of missing values in feature 'dx':\", dataframe[\"dx\"].isnull().sum())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Countplot diagnoses (dx).","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 2))\nax = sns.countplot(y=\"dx\", data=dataframe, order=dataframe['dx'].value_counts().index)\nplt.title(\"Distribution of dx with number of observations\")\n\nif hasattr(ax, 'patches'):  # Ensure ax has the 'patches' attribute\n    for p in ax.patches:\n        ax.text(p.get_width(), p.get_y() + p.get_height()/2, \n                f'{int(p.get_width())}', \n                va='center')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### dx_type","metadata":{}},{"cell_type":"markdown","source":"Unique Values, Missing Values","metadata":{}},{"cell_type":"code","source":"# Analyze feature \"dx_type\"\nprint(\"Number of unique values in feature 'dx_type':\", dataframe[\"dx_type\"].nunique())\nprint(\"Number of missing values in feature 'dx_type':\", dataframe[\"dx_type\"].isnull().sum())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Countplot kinds of diagnosis.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 1))\nax = sns.countplot(y=\"dx_type\", data=dataframe, order=dataframe['dx_type'].value_counts().index)\nplt.title(\"Distribution of dx_type with number of observations\")\n\nif hasattr(ax, 'patches'):  # Ensure ax has the 'patches' attribute\n    for p in ax.patches:\n        ax.text(p.get_width(), p.get_y() + p.get_height()/2, \n                f'{int(p.get_width())}', \n                va='center')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### age","metadata":{}},{"cell_type":"markdown","source":"Unique Values, Missing Values","metadata":{}},{"cell_type":"code","source":"# Analyze the feature \"age\"\nprint(\"Number of unique values in feature 'age':\", dataframe[\"age\"].nunique())\nprint(\"Number of missing values in feature 'age':\", dataframe[\"age\"].isnull().sum())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_ages = dataframe[dataframe[\"age\"].isnull()]\n\n# plot missing ages regarding dx and sex\nplt.figure(figsize=(10, 2))\nax = sns.countplot(y=\"dx\", data=missing_ages, hue='sex', order=missing_ages['dx'].value_counts().index)\nplt.title(\"Distribution of dx with missing age\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Mean, standard deviation, range","metadata":{}},{"cell_type":"code","source":"# Describe the feature \"age\"\ndataframe[[\"age\"]].describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Histogram of age","metadata":{}},{"cell_type":"code","source":"#plot histogram of age\nplt.figure(figsize=(8, 6))\nplt.hist(dataframe[\"age\"], bins=85, width=3, rwidth=0.5)\nplt.title(\"Distribution of age with number of observations\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"Number of observations\")\nplt.xticks(np.arange(0, 100, step=5))\n#plot mean with line and label and show value\nplt.axvline(dataframe[\"age\"].mean(), color='k', linestyle='dashed', linewidth=1)\nmin_ylim, max_ylim = plt.ylim()\nplt.text(dataframe[\"age\"].mean()*1.1, max_ylim*0.9, 'Mean: {:.2f}'.format(dataframe[\"age\"].mean()))\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Boxplot of age","metadata":{}},{"cell_type":"code","source":"# plot boxplot of age\nplt.figure(figsize=(10, 2))\nsns.boxplot(x=dataframe[\"age\"])\nplt.title(\"Boxplot of age\")\nplt.xlabel(\"Age\")\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### sex","metadata":{}},{"cell_type":"markdown","source":"Unique Values, Missing Values","metadata":{}},{"cell_type":"code","source":"#analyze the feature sex\nprint(\"Number of unique values in feature 'sex':\", dataframe[\"sex\"].nunique())\nprint(\"Number of missing values in feature 'sex':\", dataframe[\"sex\"].isnull().sum())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#count 'unknown' values in sex and print\nunknown_sex = dataframe.query(\"sex == 'unknown'\")\nprint(\"Number of unknown sex:\" , unknown_sex.shape[0])\n\n#plot unknown_sex regarding age\nplt.figure(figsize=(8, 2))\nsns.countplot(data=unknown_sex, y=\"age\")\nplt.title(\"Unknown sex and age\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"Number of observations\")\nplt.show()\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Countplot of sex","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 1))\nax = sns.countplot(y=\"sex\", data=dataframe, order=dataframe['sex'].value_counts().index)\nplt.title(\"Distribution of sex with number of observations\")\n\nif hasattr(ax, 'patches'):  # Ensure ax has the 'patches' attribute\n    for p in ax.patches:\n        ax.text(p.get_width(), p.get_y() + p.get_height()/2, \n                f'{int(p.get_width())}', \n                va='center')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### localization","metadata":{}},{"cell_type":"markdown","source":"Unique Values, Missing Values","metadata":{}},{"cell_type":"code","source":"# Analyze the feature \"age\"\nprint(\"Number of unique values in feature 'localization':\", dataframe[\"localization\"].nunique())\nprint(\"Number of missing values in feature 'localization':\", dataframe[\"localization\"].isnull().sum())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Countplot of localization","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 3))\nax = sns.countplot(y=\"localization\", data=dataframe, order=dataframe['localization'].value_counts().index)\nplt.title(\"Distribution of localization with number of observations\")\n\nif hasattr(ax, 'patches'):  # Ensure ax has the 'patches' attribute\n    for p in ax.patches:\n        ax.text(p.get_width(), p.get_y() + p.get_height()/2, \n                f'{int(p.get_width())}', \n                va='center')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### dataset","metadata":{}},{"cell_type":"markdown","source":"Unique Values, Missing Values","metadata":{}},{"cell_type":"code","source":"# Analyze the feature \"dataset\"\nprint(\"Number of unique values in feature 'dataset':\", dataframe[\"dataset\"].nunique())\nprint(\"Number of missing values in feature 'dataset':\", dataframe[\"dataset\"].isnull().sum())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Countplot of dataset","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 1))\nax = sns.countplot(y=\"dataset\", data=dataframe, order=dataframe['dataset'].value_counts().index)\nplt.title(\"Distribution of dataset with number of observations\")\n\nif hasattr(ax, 'patches'):  # Ensure ax has the 'patches' attribute\n    for p in ax.patches:\n        ax.text(p.get_width(), p.get_y() + p.get_height()/2, \n                f'{int(p.get_width())}', \n                va='center')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2 Confronting Emerging Issues - Round 1","metadata":{}},{"cell_type":"markdown","source":"#### Problem 2: Missing Values in Age column - We can either drop the rows with missing values or impute the missing values with mean/median/mode.","metadata":{}},{"cell_type":"code","source":"# show range of age\ndataframe.age.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Solution Problem 2:","metadata":{}},{"cell_type":"code","source":"# replace NaN with the mean of the age column\n#df_filled = dataframe['age'].fillna((dataframe['age'].mean()), inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"solve later","metadata":{}},{"cell_type":"markdown","source":"### 3.3 Relational Statistics","metadata":{}},{"cell_type":"code","source":"# define features as categorical\ndataframe['dx'] = dataframe['dx'].astype('category')\ndataframe['dx_type'] = dataframe['dx_type'].astype('category')\ndataframe['sex'] = dataframe['sex'].astype('category')\ndataframe['localization'] = dataframe['localization'].astype('category')\ndataframe['dataset'] = dataframe['dataset'].astype('category')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = dataframe\norder_categories = ['mel', 'bcc', 'akiec', 'nv', 'bkl', 'df', 'vasc']\n\n# Set up the figure and axes for the three plots\nfig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 6))\nfig.suptitle('Relationship Analysis of Features to Target Variable \"dx\"', fontsize=16)\n\n# Plot dx_type vs dx\nsns.countplot(data=data, x='dx_type', hue='dx', ax=axes[0], palette=\"Set2\", hue_order=order_categories)\naxes[0].set_title('dx_type vs dx')\naxes[0].set_ylabel('Count')\naxes[0].get_legend().remove()  # Remove individual legend\n\n# Plot sex vs dx\nsns.countplot(data=data, x='sex', hue='dx', ax=axes[1], palette=\"Set2\", hue_order=order_categories)\naxes[1].set_title('sex vs dx')\naxes[1].set_ylabel('Count')\naxes[1].get_legend().remove()  # Remove individual legend\n\n# Plot dataset vs dx\nsns.countplot(data=data, x='dataset', hue='dx', ax=axes[2], palette=\"Set2\", hue_order=order_categories)\naxes[2].set_title('dataset vs dx')\naxes[2].set_ylabel('Count')\naxes[2].tick_params(axis='x', rotation=45)\naxes[2].get_legend().remove()  # Remove individual legend\n\n# Add a common legend outside the grid\nhandles, labels = axes[2].get_legend_handles_labels()\nlabels = ['mel (cancer)', 'bcc (cancer)', 'akiec (cancer)', 'nv', 'bkl', 'df', 'vasc']\nfig.legend(handles=handles, labels=labels, title='dx', loc='center left', bbox_to_anchor=(1, 0.5))\n\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])\nplt.show()\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = dataframe\norder_categories = ['mel', 'bcc', 'akiec', 'nv', 'bkl', 'df', 'vasc']\n\n# Plot for localization vs dx with the legend outside the grid\nplt.figure(figsize=(14, 6))\nax_local = sns.countplot(data=data, x='localization', hue='dx', palette=\"Set2\", hue_order=order_categories)\nplt.title('localization vs dx')\nplt.ylabel('Count')\nplt.xticks(rotation=45)\n\n# Add a legend outside the grid\nhandles, labels = ax_local.get_legend_handles_labels()\nlabels = ['mel (cancer)', 'bcc (cancer)', 'akiec (cancer)', 'nv', 'bkl', 'df', 'vasc']\nplt.legend(handles=handles, labels=labels, title='dx', loc='center left', bbox_to_anchor=(1, 0.5))\n\nplt.tight_layout()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Contingency: dx vs dx_type","metadata":{}},{"cell_type":"markdown","source":"The cross table displays the relationship between \"dx\" and \"dx_type\". For some categories of \"dx\", there is only one type of \"dx_type\" (e.g., \"akiec\" and \"histo\").","metadata":{}},{"cell_type":"code","source":"# Create a contingency table for dx and dx_type\ncontingency_dx_type = pd.crosstab(dataframe['dx'], dataframe['dx_type'])\n\ncontingency_dx_type\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Contingency dx vs sex","metadata":{}},{"cell_type":"markdown","source":"The cross table shows the distribution of skin lesion types (\"dx\") in relation to gender. For example, there are 106 cases of \"akiec\" in women and 221 cases in men.","metadata":{}},{"cell_type":"code","source":"# Create a contingency table for dx and sex\ncontingency_sex = pd.crosstab(data['dx'], data['sex'])\n\ncontingency_sex","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Contingency dx vs localization","metadata":{}},{"cell_type":"markdown","source":"The cross table shows the distribution of skin lesion types (\"dx\") in relation to their localization. For example, there are 65 cases of \"akiec\" located on the lower extremities and 113 cases of \"akiec\" located on the face.","metadata":{}},{"cell_type":"code","source":"# Create a contingency table for dx and localization\ncontingency_localization = pd.crosstab(data['dx'], data['localization'])\n\ncontingency_localization","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Contingency dx vs dataset","metadata":{}},{"cell_type":"markdown","source":"The cross table shows the distribution of skin lesion types (\"dx\") based on the dataset from which they originate. For example, there are 295 cases of \"akiec\" from the \"rosendahl\" dataset and 32 cases from the \"vidir_modern\" dataset.","metadata":{}},{"cell_type":"code","source":"# Create a contingency table for dx and dataset\ncontingency_dataset = pd.crosstab(data['dx'], data['dataset'])\n\ncontingency_dataset","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Mean Age per Diagnosis","metadata":{}},{"cell_type":"markdown","source":"The bar chart shows the average age for each category of \"dx\". For instance, individuals with the diagnosis \"df\" (Dermatofibroma) have an average age that is higher than those with the diagnosis \"mel\" (Melanoma).","metadata":{}},{"cell_type":"code","source":"# Group by dx and calculate mean age\nmean_age_per_dx = data.groupby('dx')['age'].mean()\n\n# Plot the mean age for each dx category\nplt.figure(figsize=(10, 6))\nmean_age_per_dx.plot(kind='bar', color='skyblue')\nplt.title('Mean age per dx category')\nplt.ylabel('Mean age')\nplt.xlabel('dx category')\nplt.grid(axis='y')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Chi2-Test","metadata":{}},{"cell_type":"markdown","source":"Categorical data can be correlated with the target variable using the Chi-Squared Test. This test checks if there is a significant association between two categorical variables. A significant test value suggests that the variables are not independent of each other.\n\nIn the case where the target variable (\"dx\") and a categorical feature are correlated, we can use the p-value of the Chi-Squared Test to determine if the association is significant.","metadata":{}},{"cell_type":"code","source":"from scipy.stats import chi2_contingency\n\n# List of categorical features to test\nfeatures_to_test = ['dx_type', 'sex', 'localization', 'dataset']\n\n# Store p-values and test statistics\np_values = {}\ntest_statistics = {}\n\n# Perform chi2 test for each feature\nfor feature in features_to_test:\n    contingency_table = pd.crosstab(data['dx'], data[feature])\n    chi2, p, _, _ = chi2_contingency(contingency_table)\n    p_values[feature] = p\n    test_statistics[feature] = chi2\n\nprint(\"p-Values: \", p_values)\nprint(\"Test Statistics:\", test_statistics)\nprint(\"Significance level: 0.05\")\nprint(\"\")\nprint(\"Conclusion:\")\nprint(\"The null hypothesis is rejected if the p-value is less than the significance level.\")\nprint(\"The null hypothesis is that the two categorical variables (feature vs dx) are independent.\")\nprint(\"The alternative hypothesis is that the two categorical variables (feature vs dx) are dependent.\")\nprint(\"\")\nprint(\"The p-values are all less than the significance level.\")\nprint(\"Therefore, the null hypothesis is rejected for all features.\")\nprint(\"The alternative hypothesis is accepted for all features.\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The bar chart displays the Chi2 test statistics for the various features in relation to the target variable \"dx\". A higher value of the test statistic suggests a stronger association between the feature and the target variable. As you can see, all features have a significant association with \"dx\", with \"dx_type\" showing the strongest and \"sex\" showing the weakest (but still significant) association.","metadata":{}},{"cell_type":"code","source":"# Visualize the chi2 test statistics for each feature\nplt.figure(figsize=(10, 6))\nplt.bar(test_statistics.keys(), test_statistics.values(), color='salmon')\nplt.ylabel('Chi2 Test Statistic')\nplt.title('Chi2 Test Statistics for categorical features to dx')\nplt.grid(axis='y')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### dx and age","metadata":{}},{"cell_type":"markdown","source":"Boxplot age and dx","metadata":{}},{"cell_type":"code","source":"data = dataframe\n\n# Boxplot to visualize the relationship between 'age' and 'dx'\nplt.figure(figsize=(12, 8))\nsns.boxplot(data=data, x='dx', y='age', palette=\"Set2\", order=order_categories)\nplt.title('Relationship between Age and dx')\nplt.ylabel('Age')\nplt.xlabel('dx')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Based on the boxplot visualizing the relationship between 'age' and 'dx' (excluding 'nv'), we can make the following observations:\n\n1) Spread and Central Tendency:\n\n    The median age for conditions like 'akiec' seems to be higher compared to other conditions, suggesting that 'akiec' might be more prevalent among older individuals.\n    'mel' and 'bcc' also show a higher median age compared to some other conditions, but not as high as 'akiec'.\n\n2) Variability:\n\n    The age distribution for 'nv' (which was excluded in the later analysis) was broader, meaning it affects a wider age range of people.\n    The interquartile range (IQR, represented by the box's height) for conditions like 'akiec' is narrower, suggesting that the ages of patients with this condition are more concentrated around the median.\n\n3) Outliers:\n\n    There may be some outliers (points outside the whiskers of the boxplot) for some conditions, indicating ages that are unusually high or low for those conditions.\n\n4) Comparisons:\n\n    By comparing the boxes' positions and spreads, we can infer which conditions are more prevalent at younger or older ages. For instance, 'akiec' and 'mel' tend to be associated with older ages compared to conditions like 'bkl' or 'df'.\n\nIn summary, the boxplot provides insights into the age distributions associated with each 'dx' category. It suggests that certain skin conditions may be more prevalent or diagnosed at specific age ranges. The exact age distributions and their implications would need to be further investigated and validated with domain-specific knowledge and larger datasets.","metadata":{}},{"cell_type":"markdown","source":"**A more detailed look at age, localization and cancer-related diagnoses:**","metadata":{}},{"cell_type":"code","source":"data = dataframe\n\n# Filter the dataset for rows where 'dx' is 'mel', 'akiec', or 'bcc'\nfiltered_data = data[data['dx'].isin(['mel', 'akiec', 'bcc'])]\n\n# Boxplot to visualize the relationship between 'age', 'localization', and 'dx'\nplt.figure(figsize=(16, 10))\nsns.boxplot(data=filtered_data, x='localization', y='age', hue='dx', palette=\"Set2\")\nplt.title('Relationship between Age, Localization, and dx (for \"mel\", \"akiec\", and \"bcc\")')\nplt.ylabel('Age')\nplt.xlabel('Localization')\nplt.legend(title='dx')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.4 Risk Ratio","metadata":{}},{"cell_type":"markdown","source":"#### Localization and Melanoma (skin cancer 3)","metadata":{}},{"cell_type":"markdown","source":"The bar chart below shows the risk ratio for \"mel\" in relation to the various \"localization\" categories, with \"abdomen\" serving as the reference group.\nA risk ratio greater than 1 means that the risk of having an actinic carcinoma in this specific \"localization\" category is higher than in the \"abdomen\".","metadata":{}},{"cell_type":"code","source":"data = dataframe\n\n# Create a binary column for the event \"mel\"\ndata['mel_event'] = (data['dx'] == 'mel').astype(int)\n\n# Calculate the risk for each localization category\nrisk_per_localization = data.groupby('localization')['mel_event'].mean()\n\n# Choose \"abdomen\" as the reference group\nreference_risk = risk_per_localization['abdomen']\n\n# Calculate the risk ratio for each localization category\nrisk_ratios = risk_per_localization / reference_risk\n\n# Visualize the risk ratios\nplt.figure(figsize=(14, 6))\nsns.barplot(x=risk_ratios.index, y=risk_ratios.values, palette=\"viridis\")\nplt.title('Risk Ratios of \"mel\" for Different \"localization\" Categories')\nplt.ylabel('Risk Ratio')\nplt.xlabel('Localization')\nplt.axhline(y=1, color='red', linestyle='--')  # Reference line for RR=1\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Localization and basal cell carcinoma (skin cancer 2)","metadata":{}},{"cell_type":"markdown","source":"The bar chart below shows the risk ratio for \"bcc\" in relation to the various \"localization\" categories, with \"abdomen\" serving as the reference group.\nAs in the previous charts, a risk ratio greater than 1 means that the risk of having an actinic carcinoma in this specific \"localization\" category is higher than in the \"abdomen\".","metadata":{}},{"cell_type":"code","source":"data = dataframe\n\n# Create a binary column for the event \"bcc\"\ndata['bcc_event'] = (data['dx'] == 'bcc').astype(int)\n\n# Calculate the risk for each localization category\nrisk_per_localization_bcc = data.groupby('localization')['bcc_event'].mean()\n\n# Use \"abdomen\" as the reference group\nreference_risk_bcc = risk_per_localization_bcc['abdomen']\n\n# Calculate the risk ratio for each localization category\nrisk_ratios_bcc = risk_per_localization_bcc / reference_risk_bcc\n\n# Visualize the risk ratios for bcc\nplt.figure(figsize=(14, 6))\nsns.barplot(x=risk_ratios_bcc.index, y=risk_ratios_bcc.values, palette=\"viridis\")\nplt.title('Risk Ratios of \"bcc\" for Different \"localization\" Categories')\nplt.ylabel('Risk Ratio')\nplt.xlabel('Localization')\nplt.axhline(y=1, color='red', linestyle='--')  # Reference line for RR=1\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Localization and actinic keratoses and intraepithelial carcinoma / Bowen's disease (skin cancer 3)","metadata":{}},{"cell_type":"markdown","source":"The bar chart below shows the risk ratio for \"akiec\" in relation to the various \"localization\" categories, with \"abdomen\" serving as the reference group.\nAs in the previous charts, a risk ratio greater than 1 means that the risk of having an actinic carcinoma in this specific \"localization\" category is higher than in the \"abdomen\".","metadata":{}},{"cell_type":"code","source":"data = dataframe\n\n# Create a binary column for the event \"akiec\"\ndata['akiec_event'] = (data['dx'] == 'akiec').astype(int)\n\n# Calculate the risk for each localization category\nrisk_per_localization_akiec = data.groupby('localization')['akiec_event'].mean()\n\n# Use \"abdomen\" as the reference group\nreference_risk_akiec = risk_per_localization_akiec['abdomen']\n\n# Calculate the risk ratio for each localization category\nrisk_ratios_akiec = risk_per_localization_akiec / reference_risk_akiec\n\n# Visualize the risk ratios for akiec\nplt.figure(figsize=(14, 6))\nsns.barplot(x=risk_ratios_akiec.index, y=risk_ratios_akiec.values, palette=\"viridis\")\nplt.title('Risk Ratios of \"akiec\" for Different \"localization\" Categories')\nplt.ylabel('Risk Ratio')\nplt.xlabel('Localization')\nplt.axhline(y=1, color='red', linestyle='--')  # Reference line for RR=1\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4 Confronting Emerging Issues - Round 2","metadata":{}},{"cell_type":"markdown","source":"#### 1) Distribution of diagnosis","metadata":{}},{"cell_type":"markdown","source":"Target classifier is very imbalanced. We need to see if Tensorflow has problems with that. \n* Class weights - penalize the model for misclassifying minority class\n* Data Augmentation - create more samples for minority class by multiple random transformations\n* Resampling - create more samples for minority class by duplicating existing samples (SMOTE,variational autoencoders)\n* Evaluation Metrics - Accuracy is not a good metric for imbalanced datasets. We can use F1 score, precision, recall, AUC etc.","metadata":{}},{"cell_type":"markdown","source":"Solutions: Subset of equal amount of images, anomaly detection, image augmentation","metadata":{}},{"cell_type":"markdown","source":"#### 2) Distribution of location of the lesion","metadata":{}},{"cell_type":"code","source":"dataframe.localization.unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Classes like trunk include chest,back,abdomen,genital and might overlap with upper extremity. We might need to decide where to classify these lesions. Maybe we can agglumerate all these classes into one class called trunk.","metadata":{}},{"cell_type":"markdown","source":"Maybe we can agglumerate some classes together like face and ear etc.\n","metadata":{}},{"cell_type":"markdown","source":"Contingency/ relation between cancerous / non-cancerous vs the location found","metadata":{}},{"cell_type":"code","source":"# relation between localization and type of lesion\n# dropping nv because of the high number of entries\n# Filter out rows where dx is 'nv'\n# Filter out rows where dx is 'nv'\ndata_without_nv = data[data['dx'] != 'nv']\n\n# Create a contingency table for 'localization' and 'dx'\ncontingency_table = pd.crosstab(data_without_nv['localization'], data_without_nv['dx'])\n\ncontingency_table\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 2: Visualization\nplt.figure(figsize=(15, 8))\nsns.countplot(data=data_without_nv, x='localization', hue='dx', palette=\"Set2\")\nplt.title('Relationship between Localization and dx without \"nv\"')\nplt.ylabel('Count')\nplt.xlabel('Localization')\nplt.xticks(rotation=45)\nplt.legend(title='dx')\nplt.tight_layout()\nplt.show()\n\n# Step 3: Chi-Squared Test\nchi2, p, _, _ = chi2_contingency(contingency_table)\nprint(f\"Chi-Squared Value: {chi2}\")\nprint(f\"P-Value: {p}\")\nif p < 0.05:\n    print(\"The relationship between localization and dx (without nv) is statistically significant.\")\nelse:\n    print(\"There's no statistically significant relationship between localization and dx (without nv).\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3) Distribution of Age and Sex","metadata":{}},{"cell_type":"markdown","source":"#### 4) Distribution of type of ground truth","metadata":{}},{"cell_type":"markdown","source":"distribution between cancerous/ non cancerous\ndo lesion_id/image_id come up again in dx_type follow up","metadata":{}},{"cell_type":"markdown","source":"can think about making two classes the doctor's praxis or the laboratory(confocal/histo)","metadata":{}},{"cell_type":"markdown","source":"# Mod. Image Loader with Albumentation","metadata":{}},{"cell_type":"markdown","source":"Description: This notebook loads images from a directory, and handles imbalanced classes with down/re/upsampling and augmentation.\n\nThis notebook should be run from the top to the bottom, resulting in 3 files:\n\n* `train_from_Metadata_processed.csv` - a csv file with the training data\n* `validation_from_Metadata_processed.csv` - a csv file with the validation data\n* `test_from_Metadata_processed.csv` - a csv file with the test data\n\nThese files encode the images with labels.\n","metadata":{}},{"cell_type":"markdown","source":"## Imports and inital setup","metadata":{}},{"cell_type":"code","source":"# Imports\nimport pandas as pd\n\nfrom albumentations import (Compose, RandomCrop, Normalize, HorizontalFlip, Resize, RandomBrightnessContrast, CoarseDropout, GridDistortion, HueSaturationValue, GaussianBlur, Rotate, RandomResizedCrop)\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\n\nimport os\nimport random\nimport sys\n\nsys.path.append(\"..\")\nfrom helperfunctions import imagehelper as ih\n\nSEED = 4932\n\nMAX_SAMPLES_TRAIN = 750\nMAX_SAMPLES_VAL = int(MAX_SAMPLES_TRAIN * 0.33)\n\n# File path variables\n# please make sure to use the correct path to the meta data file\nFILEPATH_JPGS = './../data/jpgs/'\nFILEPATH_METADATA=\"/kaggle/working/processed/Metadata_processed.csv\"\nFILEPATH_OUTPUT = './../data/jpgs/' \n\nTARGET_LABEL=\"dx_tertiary\"    # Needed for test train split\nBALANCE_LABEL=\"dx\"          # Needed for balancing the dataset\nIMAGE_SIZE = (224, 224)     # Adapt to your model!","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Deleting all previously augmented images in advance","metadata":{}},{"cell_type":"code","source":"# Define the bash script as a string\nbash_script = \"\"\"\n#!/bin/bash\n\noutput_folder=\"./../data/jpgs/\" \n\n# Delete images with the \"aug_\" prefix\nfind \"$output_folder\" -type f -name \"aug_*\" -delete\n\necho \"Deleted augmented images with 'aug_' prefix in $output_folder\"\n\"\"\"\n\n# Save the bash script to a file\nwith open('delete_augmented_images.sh', 'w') as script_file:\n    script_file.write(bash_script)\n\n# Make the script executable\n!chmod +x delete_augmented_images.sh\n\n# Execute the script\n!./delete_augmented_images.sh\n\n# Delete the script\n!rm delete_augmented_images.sh","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loading the metadata file","metadata":{}},{"cell_type":"code","source":"# Read the metadata file\nmetadata = pd.read_csv(FILEPATH_METADATA)\n\n# Concatenate the base directory with the image filename to add the full path\nmetadata['image_path'] = FILEPATH_JPGS + metadata['image_id']\n\nmetadata.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Splitting the data in train, validation and test sets","metadata":{}},{"cell_type":"code","source":"# Splitting the data into train, validation and test using train_test_split\n\n# Split the data into two subsets: train and temp (80% train, 20% temp)\ntrain_df, temp_df = train_test_split(metadata, test_size=0.2, stratify=metadata[TARGET_LABEL], random_state=SEED)\n\n# Split the temp data into validation and test sets (50% each)\nvalidation_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df[TARGET_LABEL], random_state=SEED)\n\n# resetting the index\ntrain_df = train_df.reset_index(drop=True)\nvalidation_df = validation_df.reset_index(drop=True)\ntest_df = test_df.reset_index(drop=True)\n\ndisplay(\n    train_df.shape,\n    validation_df.shape,\n    test_df.shape\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Showing the number of samples per BALANCE_LABEL in train, validation and test set\nprint(\"Samples per class in train set:\")\nprint(train_df[BALANCE_LABEL].value_counts())\nprint(\" \")\nprint(\"Samples per class in val set:\")\nprint(validation_df[BALANCE_LABEL].value_counts())\nprint(\" \")\nprint(\"Samples per class in test set:\")\nprint(test_df[BALANCE_LABEL].value_counts())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tackling Class imbalances in the training set","metadata":{}},{"cell_type":"markdown","source":"## Setting up the image data generator for augmentation","metadata":{}},{"cell_type":"code","source":"# Using albumentations to augment the data\n\ndatagen_augment = Compose([\n    HorizontalFlip(p=0.5),\n    Rotate(limit=45, p=0.5),\n    RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n    RandomResizedCrop(always_apply=False, p=0.5, scale=(0.75, 0.85), interpolation=0, height=IMAGE_SIZE[0], width=IMAGE_SIZE[1]),\n    # HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n    # GaussianBlur(blur_limit=(3, 7), p=0.5),\n    # CoarseDropout(max_holes=12, min_height= 3 ,max_height=12,min_width=3, max_width=12, p=0.5),\n])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparing data for augmentation","metadata":{}},{"cell_type":"code","source":"def df_balancer_augmentation(df, datagen_augment, balance_label, max_samples, image_size, output_filepath, seed=42) -> pd.DataFrame:\n    \"\"\"\n    This function takes a DataFrame and applies data augmentation to balance the classes.\n    The function returns a new DataFrame with the augmented data.\n    Args:\n        df: DataFrame to be balanced\n        datagen_augment: Augmentation generator\n        balance_label: Column name of the column with the class labels which will be balanced\n        max_samples: Maximum number of samples per class\n        image_size: Size of the images\n        output_filepath: Filepath to save the augmented images\n    Returns:\n        balanced_train_df: DataFrame with the augmented data\n    \"\"\"\n    # print what function is going to do\n    print(f\"Balancing and augmenting data frame using label:{balance_label} to {max_samples} samples per class...\\n\")\n\n    # Create separate DataFrames for every class in the given BALANCE_LABEL column\n\n    class_dataframes = {}\n    for class_label in df[balance_label].unique():\n        class_dataframes[class_label] = df[df[balance_label] == class_label]\n        # print(f\"Class {class_label} has {class_dataframes[class_label].shape[0]} samples\")\n\n    # Initialize a dictionary to keep track of the number of augmented images per class\n    class_augmentation_counts = {class_label: 0 for class_label in class_dataframes.keys()}\n\n    # Create a list to store newly generated DataFrames for each class\n    augmented_dataframes = []\n\n    # Apply data augmentation for classes with few examples, trim classes with too many examples\n    for class_label, class_df in class_dataframes.items():\n        \n        # Describing the overall progress\n        print(f\"\\nChecking class {class_label}...\")\n\n        # Calculate the number of images needed to reach MAX_SAMPLES for this class\n        images_needed = max_samples - class_df.shape[0]\n        \n        # If images_needed is negative, randomly select MAX_SAMPLES from the class_df\n        if images_needed < 0:\n            print(f\"> Result: Class {class_label} was reduced to {max_samples} samples\")\n            reduced_df = class_df.sample(n=max_samples, random_state=seed)\n            augmented_dataframes.append(reduced_df)\n            continue\n        # If images_needed is zero, skip this class\n        elif images_needed == 0:\n            print(f\"> Result: Class {class_label} already has exactly {max_samples} samples\")\n            augmented_dataframes.append(class_df)\n            continue\n\n        # Generate augmented data - this part only runs if images_needed is positive\n        print(f\"> Result: Class {class_label} needs {images_needed} more images\")\n        augmented_dataframes.append(class_df)\n\n        while class_augmentation_counts[class_label] <= images_needed:\n\n            # Describing the subprocess progress for each class\n            sys.stdout.write(f\"\\rProgress: {class_augmentation_counts[class_label]}/{images_needed}\")\n            sys.stdout.flush()\n\n            # Randomly select an image from the class_df\n            i = random.randint(0, class_df.shape[0] - 1)\n            image_path = class_df.iloc[i]['image_path']\n\n            # Load and preprocess the image\n            img = ih.img_load_and_transform(image_path, image_size)\n\n            # Apply data augmentation via generator\n            augmented_img = datagen_augment(image=img)['image']\n\n            # Create a new image ID with prefix\n            augmented_image_id = f'aug_{ih.generate_random_string()}' + os.path.basename(image_path)\n\n            # Create a new image path with the augmented image ID as string\n            augmented_image_path = output_filepath + augmented_image_id\n            \n            # Create a new DataFrame for the augmented data for this instance only\n            augmented_instance_df = class_df.iloc[i:i+1].copy()\n            \n            # Reset the index of the new DataFrame\n            augmented_instance_df.reset_index(drop=True, inplace=True)\n\n            # Update the \"image_id\" column with the augmented image ID\n            augmented_instance_df.at[0, 'image_id'] = augmented_image_id\n            \n            # Update the \"image_path\" column with the augmented image path\n            augmented_instance_df.at[0, 'image_path'] = augmented_image_path\n            \n            # Append the augmented DataFrame for this instance to the list\n            augmented_dataframes.append(augmented_instance_df)\n\n            # Save the augmented image to the output folder\n            augmented_image_path = os.path.join(output_filepath, augmented_image_id)\n            plt.imsave(augmented_image_path, augmented_img)\n\n            # Update the counter for the class\n            class_augmentation_counts[class_label] += 1\n\n    # Combine all augmented DataFrames into a single DataFrame\n    balanced_train_df = pd.concat(augmented_dataframes, ignore_index=True)\n\n    return balanced_train_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply the data augmentation function to the train_df\nbalanced_train_df = df_balancer_augmentation(train_df, datagen_augment, BALANCE_LABEL, MAX_SAMPLES_TRAIN, IMAGE_SIZE, FILEPATH_OUTPUT)\n\n# Display the shape of the new DataFrame\nprint(f\"\\nShape of the balanced train DataFrame: {balanced_train_df.shape}\")\n\n# Currently not applying data augmentation to the validation set after Input by coach\nbalanced_validation_df = validation_df\n# balanced_validation_df = df_balancer_augmentation(validation_df, datagen_augment, BALANCE_LABEL, MAX_SAMPLES_VAL, IMAGE_SIZE, FILEPATH_OUTPUT)\n\n# Display the shape of the new DataFrame\nprint(f\"\\nShape of the balanced validation DataFrame: {balanced_validation_df.shape}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Showing the number of samples per BALANCE_LABEL in train, validation and test set\nprint(\"Samples per class in train set:\")\nprint(balanced_train_df[BALANCE_LABEL].value_counts())\n\nprint(\"\\nSamples per class in val set:\")\nprint(balanced_validation_df[BALANCE_LABEL].value_counts())\n\nprint(\"\\nSamples per class in test set:\")\nprint(test_df[BALANCE_LABEL].value_counts())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking the image file folder","metadata":{}},{"cell_type":"code","source":"# Checking what's going on in the folder\n\ndef count_files_in_folder(folder_path):\n    # Initialize counters\n    total_files = 0\n    aug_files = 0\n\n    # Check if the folder exists\n    if os.path.exists(folder_path):\n        # List all files in the folder\n        files = os.listdir(folder_path)\n        \n        # Count all files and files starting with \"aug_\"\n        for file in files:\n            total_files += 1\n            if file.startswith(\"aug_\"):\n                aug_files += 1\n\n        # Display the counts\n        print(f\"Total files in folder: {total_files}\")\n        print(f\"Files starting with 'aug_': {aug_files}\")\n    else:\n        print(f\"Folder '{folder_path}' does not exist.\")\n\n# Example usage:\nfolder_path = \"./../data/jpgs/\"  # Replace with your folder path\ncount_files_in_folder(folder_path)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get a random sample of 9 images from the balanced_train_df\nsample_df = balanced_train_df.sample(n=9, random_state=543)\n\n# Create a list of image paths from the \"image_path\" column\nimage_paths = sample_df['image_path'].tolist()\n\n# Create a list of image labels from the \"dx\" column\nimage_labels = sample_df['dx'].tolist()\n\n# Load and plot the images without imagehelper\nfig, axes = plt.subplots(3, 3, figsize=(10, 10))\naxes = axes.ravel()\nfor i, image_path in enumerate(image_paths):\n    img = plt.imread(image_path)\n    axes[i].imshow(img)\n    axes[i].set_title(image_labels[i])\n    axes[i].axis('off')\n\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Saving Test, Validation and Training data to csv","metadata":{}},{"cell_type":"code","source":"balanced_train_df.to_csv('../data/processed/train_from_Metadata_processed.csv', index=False)\nbalanced_validation_df.to_csv('../data/processed/validation_from_Metadata_processed.csv', index=False)\ntest_df.to_csv('../data/processed/test_from_Metadata_processed.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN pretrained ResNet50 model ","metadata":{}},{"cell_type":"markdown","source":"Source of idea: https://www.ejcancer.com/article/S0959-8049(19)30349-1/fulltext#secsectitle0050 Chapter 2.2 Methods","metadata":{}},{"cell_type":"markdown","source":"#### Pretrained ResNet50 CNN:\n\n* ResNet50 Model: ResNet50 is a deep convolutional neural network architecture originally designed for image classification tasks. It consists of 50 layers, including convolutional layers, batch normalization, and skip connections (residual connections), which allow it to effectively learn from very deep networks. The model is pretrained on a large dataset (typically ImageNet) to capture a wide range of features from images\n\n* Transfer Learning: In transfer learning, we start with a pretrained model (ResNet50 in this case) and fine-tune it for a specific task. By doing this, we leverage the knowledge the model has gained from the original dataset and adapt it to a new task, such as classifying skin lesions","metadata":{}},{"cell_type":"markdown","source":"## Imports and loading Data","metadata":{}},{"cell_type":"code","source":"# Imports\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\nfrom keras import backend as K\nfrom tensorflow.keras.applications import MobileNetV3Large\nfrom tensorflow.keras.applications.mobilenet_v3 import preprocess_input\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.metrics import AUC, Precision, Recall\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.optimizers.legacy import SGD\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\nfrom time import sleep \n\nimport cv2\nimport sys\nimport os\n\nsys.path.append(\"..\")\nfrom helperfunctions import modelhelper as mh\nfrom helperfunctions import imagehelper as ih\n\nSEED = 226\nNUM_EPOCHS = 20\n\n# File path variables\n# please make sure to use the correct path to the meta data file\n\nFILEPATH_JPGS = './../data/jpgs/'\nFILEPATH_PROCESSED=\"./../data/processed/\"\nFILEPATH_OUTPUT = './../data/jpgs/'  # Replace with your folder path\nFIELPATH_TESTOUTPUT= \"./../data/testoutput/\"\n\nTARGET_LABEL=\"dx_tertiary\"\n\nIMAGE_SIZE = (224, 224)\n\nBATCH_SIZE = 32","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loading (augmented) metadata as test, train, validation from files","metadata":{}},{"cell_type":"code","source":"# Read the metadata file\ntrain_df = pd.read_csv(FILEPATH_PROCESSED+\"train_from_Metadata_processed.csv\")\nvalidation_df = pd.read_csv(FILEPATH_PROCESSED+\"validation_from_Metadata_processed.csv\")\ntest_df = pd.read_csv(FILEPATH_PROCESSED+\"test_from_Metadata_processed.csv\")\n\ntrain_df.sample(15)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setting up the image data generator for training and validation","metadata":{}},{"cell_type":"markdown","source":"#### Function for custom preprocessing of the images","metadata":{}},{"cell_type":"code","source":"def custom_preprocessing(np_image, image_size, show_image=False):\n    # print the image\n    # print(\"From custom_preprocessing: Image + shape before preprocessing:\", np_image.shape)\n    np_image = np_image.astype(np.uint8)\n    \n    #print(np_image)\n    if show_image:\n        plt.imshow(np_image.astype(np.uint8))\n        plt.show()\n\n    # rescale \n    np_image = np_image / 255.0\n\n    # Using the image helper functions\n    np_image = ih.center_crop_image(np_image) # Crop image to square format\n    \n    if show_image:\n        print(\"From custom_preprocessing: Image after center crop:\", np_image.shape)\n        plt.imshow(np_image)\n        plt.show()\n\n    np_image = ih.resize_as_preprocess(np_image, image_size) # resize the image\n\n    if show_image:\n        print(\"From custom_preprocessing: Image after after resizing:\", np_image.shape)\n        plt.imshow(np_image)\n        plt.show()\n\n    return np_image","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Data Image generator for Train and Validation","metadata":{}},{"cell_type":"code","source":"# Setting up the Image Data Generator for the train data set\n\ndatagen_train = ImageDataGenerator(\n    preprocessing_function=lambda x: custom_preprocessing(x, IMAGE_SIZE), # Apply the custom preprocessing function \n    horizontal_flip=True,        # Randomly flip images horizontally\n    vertical_flip=True,          # Randomly flip images vertically\n    zoom_range=0.2,              # Randomly zoom in and out by up to 20%\n    width_shift_range=0.2,       # Randomly shift images horizontally by up to 20%\n    height_shift_range=0.2,      # Randomly shift images vertically by up to 20%\n    rotation_range=30,           # Randomly rotate images by up to 30 degrees\n    shear_range=0.2,             # Shear intensity (shear angle in radians)\n    fill_mode='nearest'          # Strategy for filling in newly created pixels after transformations\n)\n\ndatagen_validation = ImageDataGenerator(\n    preprocessing_function=lambda x: custom_preprocessing(x, IMAGE_SIZE)\n)\n\ntrain_data_generator = datagen_train.flow_from_dataframe(\n    dataframe=train_df,\n    color_mode='rgb',\n    directory=FILEPATH_JPGS,\n    target_size=IMAGE_SIZE,\n    #save_to_dir=FILEPATH_OUTPUT,\n    #save_prefix=\"test_gen_\",\n    #save_format=\"jpg\",\n    x_col=\"image_id\",\n    y_col=TARGET_LABEL,\n    class_mode=\"categorical\",\n    batch_size=BATCH_SIZE,\n)\n\nvalidation_generator = datagen_validation.flow_from_dataframe(\n    dataframe=validation_df,\n    directory=FILEPATH_JPGS,\n    target_size=IMAGE_SIZE,\n    color_mode='rgb',\n    x_col=\"image_id\",\n    y_col=TARGET_LABEL,\n    class_mode=\"categorical\",\n    batch_size=BATCH_SIZE\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Control: Show some images from the train data set after preprocessing","metadata":{}},{"cell_type":"code","source":"def show_image_samples(gen):\n    t_dict = gen.class_indices\n    classes = list(t_dict.keys())    \n    images, labels = next(gen)  \n    plt.figure(figsize=(25, 25))\n    length = len(labels)\n    if length < 25:  \n        r = length\n    else:\n        r = 25\n    for i in range(r):        \n        plt.subplot(5, 5, i + 1)\n        image = images[i]  \n        plt.imshow(image)\n        index = np.argmax(labels[i])\n        class_name = classes[index]\n        plt.title(class_name, color='blue', fontsize=18)\n        plt.axis('off')\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images, labels = next(train_data_generator)\nprint(images.min(), images.max(), images.dtype)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_image_samples(train_data_generator)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ResNet50\n","metadata":{}},{"cell_type":"markdown","source":"#### F1 score metric function for model compilation","metadata":{}},{"cell_type":"code","source":"def f1_score(y_true, y_pred):\n    # Calculate precision\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n\n    # Calculate recall\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n\n    # Calculate F1 score\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### focal loss function for model compilation (not yet in use)","metadata":{}},{"cell_type":"code","source":"def focal_loss(alpha=0.25, gamma=2.0):\n    def focal_loss_fixed(y_true, y_pred):\n        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1 + K.epsilon())) \\\n               -K.sum((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0 + K.epsilon()))\n    return focal_loss_fixed","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Model architecture","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Conv2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam, SGD\nimport math\n\n# Create a base ResNet50 model\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3)) # use the pretrained weights of the imagenet dataset, include_top=False means that we do not want to include the last layer of the model\nnum_classes = len(train_data_generator.class_indices) \n\n# Freeze layers in the base model\nfor layer in base_model.layers:\n    layer.trainable = True\n\n# Add custom layers for classification\nx = base_model.output\nx = Conv2D(64, (3, 3), activation='relu')(x)\nx = GlobalAveragePooling2D()(x) # GlobalAveragePooling2D reduces the spatial dimensions of the output\n#x = Dense(128, activation='relu')(x)\n#x = Dropout(0.5)(x) \n#x = Conv2D(64, (3, 3), activation='relu')(x) --> this made things worse... could still be interesting to add a conv block here though...\n#x = GlobalAveragePooling2D()(x) # GlobalAveragePooling2D reduces the spatial dimensions of the output\n#x = Dense(1024, activation='relu')(x) # fully connected layer with 1024 neurons and ReLU activation, relu is used to introduce non-linearity\nx= Dense(num_classes, activation='softmax')(x)\n\n# Create the final model\nmodel = Model(inputs=base_model.input, outputs=x, name='Resnet50_tertiary_augmentation_in_train_data_generator')\n\n# Compile the model with a custom optimizer (SGD with momentum)\ncustom_optimizer = tf.keras.optimizers.SGD(lr=1e-2, momentum=0.9)\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy',f1_score, Recall()])\n\n# Print model summary\nmodel.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Callback functions","metadata":{}},{"cell_type":"markdown","source":"#### Learning rate scheduler for model compilation","metadata":{}},{"cell_type":"code","source":"#defining a learning rate scheduler\nimport math\nfrom tensorflow.keras.callbacks import LearningRateScheduler\n\n# Define a learning rate schedule function\ndef lr_schedule(epoch):\n    \"\"\"\n    Learning rate schedule function.\n    \n    Args:\n        epoch (int): The current epoch number.\n        \n    Returns:\n        float: The learning rate for the current epoch.\n    \"\"\"\n    initial_lr = 0.001  # Initial learning rate\n    target_lr = 2.5e-05  # Target learning rate for warmup\n    warmup_epochs = 10  # Number of epochs for warmup\n    drop = 0.8  # Learning rate drop factor\n    epochs_drop = 4  # Number of epochs after which learning rate will drop\n\n    #During the first 10 epochs, the learning rate will gradually increase from a very low value to the target warmup value (target_lr). \n    #After the warmup phase, the original learning rate schedule takes over.\n\n    # Warmup phase\n    if epoch < warmup_epochs: \n        return initial_lr + (target_lr - initial_lr) * epoch / warmup_epochs\n    # After warmup, use the original schedule\n    else:\n        return initial_lr * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n\n\n# Create a LearningRateScheduler callback\nlr_scheduler = LearningRateScheduler(lr_schedule)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Class weights ","metadata":{}},{"cell_type":"code","source":"from sklearn.utils import class_weight\nimport numpy as np\nclass_weights = class_weight.compute_class_weight('balanced',\n                                                 classes=np.unique(train_df[TARGET_LABEL]),\n                                                    y=train_df[TARGET_LABEL])\nclass_weights = dict(enumerate(class_weights))\nclass_weights","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Reducing LR On Plateau","metadata":{}},{"cell_type":"markdown","source":"If the validation loss plateaus, the learning rate will be reduced.","metadata":{}},{"cell_type":"code","source":"# ReduceLROnPlateau\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.5,\n    patience=5,\n    min_lr=1e-6,\n    verbose=1\n    )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Early stopping","metadata":{}},{"cell_type":"markdown","source":"If the model's validation accuracy doesn't improve for 5 epochs, training will halt and revert to the best weights.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n\n# Define the early stopping callback\nearly_stopping = EarlyStopping(\n    monitor='val_accuracy',  # Metric to monitor for early stopping\n    patience=5,         # Number of epochs with no improvement to wait before stopping\n    verbose=1,          # Whether to log the stopping condition or not\n    restore_best_weights=True  # Restore the model weights to the best epoch\n    # set range in loss function\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(\n    train_data_generator,  # Training data generator\n    epochs=NUM_EPOCHS,  # Number of training epochs\n    verbose=1,  # Verbosity level during training (0, 1, or 2)\n    batch_size=BATCH_SIZE,  # Batch size for training\n    callbacks=[lr_scheduler, early_stopping, reduce_lr],  # Updated callbacks list\n    validation_split=0.0,  # Fraction of the training data to use as validation data (0.0 means no split)\n    validation_data=validation_generator,  # Validation data generator\n    shuffle=True,  # Shuffle the training data before each epoch\n    sample_weight=None,  # Optional sample weights for training data\n    class_weight=class_weights,  # Optional class weights for loss calculation\n    initial_epoch=0,  # Initial training epoch (useful for resuming training)\n    steps_per_epoch=None,  # Number of steps per epoch (default is len(x_train) // batch_size)\n    validation_steps=None,  # Number of steps for validation (default is len(x_val) // batch_size)\n    validation_batch_size=None,  # Batch size for validation (default is batch_size)\n    validation_freq=1,  # Frequency to validate the model on the validation set\n    max_queue_size=10,  # Maximum size of the generator queue\n    workers=-1,  # Maximum number of processes to generate data in parallel (-1 means all CPUs)\n    use_multiprocessing=False  # Use multiprocessing for data generation (True or False)\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plotting accuracy and loss of train and validation set","metadata":{}},{"cell_type":"markdown","source":"#### Plotting Accuracy  of train and validation set","metadata":{}},{"cell_type":"code","source":"# plotting accuracy of train and validation\nimport matplotlib.pyplot as plt\nmh.model_plot_accuracy(history)\nplt.ylim(0,1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### F1 Score of train and validation set","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Assuming you have a variable named 'history' containing the training history\n# (e.g., history = model.fit(...) where model is your Keras model)\n# You can access the loss values from 'history.history'\n\n# Plot the loss functions\nplt.plot(history.history['f1_score'], label='Training F1 Score')\nplt.plot(history.history['val_f1_score'], label='Validation F1 Score')\nplt.xlabel('Epoch')\nplt.ylabel('F1 Score')\nplt.ylim([0, 1])  # Set the y-axis limits as needed\nplt.legend(loc='lower right')  # You can adjust the legend position\nplt.show()  # Show the plot","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Plotting Loss of train and validation set","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Plot the loss functions\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.ylim([0, 3])  # Set the y-axis limits as needed\nplt.legend(loc='upper right')  # You can adjust the legend position\nplt.show()  # Show the plot\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluating the model on the test set","metadata":{}},{"cell_type":"code","source":"mh.model_accuracy_on_test(model, test_df, TARGET_LABEL, IMAGE_SIZE)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Saving the model","metadata":{}},{"cell_type":"code","source":"from datetime import datetime\ntimestamp = datetime.now()\nmodel_path = f\"../models/model_{timestamp}.h5\"\nmodel.save(model_path)","metadata":{},"execution_count":null,"outputs":[]}]}